<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>InfluxDB Blog</title>
  <subtitle>Blog posts from the team at InfluxDB</subtitle>
  <id>http://influxdb.org/blog</id>
  <link href="http://influxdb.org/blog"/>
  <link href="http://influxdb.org/feed.xml" rel="self"/>
  <updated>2014-09-25T20:00:00-04:00</updated>
  <author>
    <name>InfluxDB</name>
  </author>
  <entry>
    <title>One year of InfluxDB and the road to 1.0</title>
    <link rel="alternate" href="http://influxdb.org/blog/2014/09/26/one-year-of-influxdb-and-the-road-to-1_0.html"/>
    <id>http://influxdb.org/blog/2014/09/26/one-year-of-influxdb-and-the-road-to-1_0.html</id>
    <published>2014-09-25T20:00:00-04:00</published>
    <updated>2014-09-26T06:26:17-04:00</updated>
    <author>
      <name>Paul Dix</name>
    </author>
    <content type="html">&lt;p&gt;I&amp;rsquo;m sitting in a Starbucks in Tokyo as I write this. I&amp;rsquo;m here because &lt;a href="https://github.com/chobie"&gt;Shuhei Tanuma&lt;/a&gt;, a developer at GREE, has invited me to give a talk about our experiences developing InfluxDB in Golang at a &lt;a href="https://atnd.org/events/55464"&gt;GREE tech event&lt;/a&gt;. Shuhei is also one of the 47 contributors we&amp;rsquo;ve had issue pull requests to the core of InfluxDB in the last year. He&amp;rsquo;s using InfluxDB to store server and application performance data at GREE, a mobile social gaming company that&amp;rsquo;s publicly traded on the Tokyo stock exchange.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s hard to imagine that only a year ago this project didn&amp;rsquo;t exist.&lt;/p&gt;

&lt;p&gt;&lt;img alt="first commit" src="/images/first_commit.png" /&gt;&lt;/p&gt;

&lt;p&gt;Now that a year has gone by I wanted to take the opportunity to reflect on our path and look ahead to what we need to accomplish to get to version 1.0 of InfluxDB.&lt;/p&gt;

&lt;h3 id="the-tale-of-a-pivot"&gt;The tale of a pivot&lt;/h3&gt;

&lt;p&gt;The genesis of InfluxDB starts well before that first commit. In the fall of 2012, Todd Persen and I applied to Y Combinator for the W13 batch. We were accepted for a project we were working on called Errplane, a real-time metrics and monitoring SaaS application. As part of the YC application process you&amp;rsquo;re asked to list any other ideas you might want to work on. Our only other idea was &amp;ldquo;an open source time series database.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;We got into YC and spent the entire time working on Errplane. Afterwards, we raised a seed round of funding and continued to work on Errplane until that first InfluxDB commit. However, we had to build something like InfluxDB before we could build Errplane. The evolution of the Errplane API is one of the things that led us directly to InfluxDB.&lt;/p&gt;

&lt;p&gt;The first version of Errplane from 2012 was built on top of web services written in Scala using Cassandra to store metrics and time series data. This is a common use case for Cassandra and it&amp;rsquo;s not the first time I&amp;rsquo;ve built a &amp;ldquo;time series database&amp;rdquo; on top of it. Around the end of 2012 we had the idea that we&amp;rsquo;d want to do on-premise deployments of the application. We figured we&amp;rsquo;d need to have an architecture that was a little more self contained so we started looking at rewriting it in Go.&lt;/p&gt;

&lt;p&gt;Version 2.0 of the Errplane API was written Go using LevelDB as the underlying storage engine (two technologies that InfluxDB relies on).&lt;/p&gt;

&lt;p&gt;&lt;img alt="errplane api commit" src="/images/errplane_api_commit.png" /&gt;&lt;/p&gt;

&lt;p&gt;Over the next 10 months we improved the Errplane API and pushed out two major versions. In its original design the API consisted of three separate services. One for data collection with a pub-sub mechanism, one for counting and aggregating (like StatsD), and a service for answering queries. The API was somewhat RESTful and could store both metrics and events data.&lt;/p&gt;

&lt;p&gt;While we thought the API was cool, Errplane as a product wasn&amp;rsquo;t taking off like we hoped it would. We knew there was a lot of work to do and features that users were expecting, but we were resource constrained and trying to take on too many things at the same time. However, we did have some people paying us for the service that were very enthusiastic about what we were doing. So we dug into how they were using the product. As it turned out, they were using our API like a time series database.&lt;/p&gt;

&lt;h3 id="open-source-time-series-databases-are-a-ghetto"&gt;Open source time series databases are a ghetto&lt;/h3&gt;

&lt;p&gt;Late in the summer of 2013 we started thinking about making a drastic shift in our strategy. The time series database angle looked interesting so we checked out what other people were doing. In the closed source world there are countless examples. In fact, almost any monitoring, APM, metrics, or analytics company has had to roll their own time series solution from scratch. Most of these are exposed as APIs that customers can use directly outside of the actual product, but very few developers outside the companies that produce these APIs use them. &lt;/p&gt;

&lt;p&gt;In the open source world we found Graphite and OpenTSDB. While the approach each project takes is a little different, both have some great features. Graphite also looked like it had a fairly large user base that was continuing to grow.&lt;/p&gt;

&lt;p&gt;Despite Graphite&amp;rsquo;s popularity and the growing need in many organizations to handle time series data, neither of these projects were being pushed forward at any level approaching other open source projects like Cassandra, Riak, Mongo, or Hadoop. I talked to users of Graphite and the two most common complaints I heard were that it was a pain to install and that it didn&amp;rsquo;t scale well. The few OpenTSDB users I talked to complained about having to run an HBase cluster and that it was too easy to create hot spots that would kill performance.&lt;/p&gt;

&lt;p&gt;We started seriously considering the open source time series database idea we had put in our YC application. The final moment of realization came for me in Berlin in September of 2013 at the &lt;a href="http://monitorama.eu"&gt;Monitorama conference&lt;/a&gt;. I signed up to attend and even had Errplane sponsor the event so I could present something new we were working on. I thought it might be a good place to meet potential customers.&lt;/p&gt;

&lt;p&gt;What I found instead was that half of the attendees were employees and entrepreneurs at monitoring, metrics, DevOps, and server analytics companies. Most of them had a story about how their metrics API was their key intellectual property that took them years to develop. The other half of the attendees were developers at larger organizations that were rolling their own DevOps stack from a collection of open source tools. Almost all of them were creating a &amp;ldquo;time series database&amp;rdquo; with a bunch of web services code on top of some other database or just using Graphite.&lt;/p&gt;

&lt;p&gt;When everyone is repeating the same work, it&amp;rsquo;s not key intellectual property or a differentiator, it&amp;rsquo;s a barrier to entry. Not only that, it&amp;rsquo;s something that is hindering innovation in this space since everyone has to spend their first year or two getting to the point where they can start building something real. It&amp;rsquo;s like building a web company in 1998. You have to spend millions of dollars and a year building infrastructure, racking servers, and getting everything ready before you could run the application. Monitoring and analytics applications should not be like this.&lt;/p&gt;

&lt;p&gt;If so many people had the time series use case it seemed there was an opportunity to create a standard open platform. So I traveled back from Berlin and nervously announced to Todd and John that I thought we should start the open source project. They were both concerned about making such a drastic move, but we had a little bit of wiggle room. We figured that we could test the idea out in about two months. We had to make the choice to either continue pushing a boulder uphill with Errplane or take a risk that the open source time series database was something people needed and there was room for another player.&lt;/p&gt;

&lt;h3 id="influxdb-gets-announced-to-the-world"&gt;InfluxDB gets announced to the world&lt;/h3&gt;

&lt;p&gt;We decided to take some lessons we learned from the Errplane API and start a fresh project. We worked on InfluxDB without really telling anyone other than our investors what we were doing for about 4 weeks. After that I thought we were far enough along to start talking about it and get some feedback on the API. I arranged to give talks at the &lt;a href="http://www.meetup.com/NYC-rb/events/141323452/"&gt;NYC Ruby Meetup&lt;/a&gt; and the &lt;a href="http://www.meetup.com/nyhackr/events/148609252/"&gt;NY Open Statistical Programming Meetup&lt;/a&gt;. Word got out about the project. O&amp;#39;Reilly posted a link on their &lt;a href="http://radar.oreilly.com/2013/11/four-short-links-5-november-2013.html"&gt;Radar Blog&lt;/a&gt;. Someone posted the documentation site to Hacker News where it stayed on the front page for most of the day.&lt;/p&gt;

&lt;p&gt;Since then I&amp;rsquo;ve received an incredible amount of encouragement on what we&amp;rsquo;re building. I&amp;rsquo;ve been invited to give talks at the NY League of Professional Systems Administrators, Boston Ruby, Dropbox, a meetup in Charlottesville organized by &lt;a href="https://vividcortex.com/"&gt;Vivid Cortex&lt;/a&gt;, SF Data Engineers, Pivtol Tech Talks, Square, Data Dog, CloudFlare, Monitorama, GREE, Paris Data Geeks, and probably a few others I&amp;rsquo;m forgetting. I think I&amp;rsquo;ve given about 22 talks about InfluxDB in the past 12 months.&lt;/p&gt;

&lt;p&gt;Luckily, I wasn&amp;rsquo;t alone. Members of the growing InfluxDB community have given talks around the world including ones in &lt;a href="https://speakerdeck.com/smly/influxdb-and-leveldb-inside-out"&gt;Kyoto&lt;/a&gt;, &lt;a href="http://www.meetup.com/devops-sydney/events/118488982/"&gt;Sydney&lt;/a&gt;, &lt;a href="http://www.colognerb.de/topics/zeitreihendaten-mit-influxdb"&gt;Cologne&lt;/a&gt;, and &lt;a href="https://2014.nosql-matters.org/dub/abstracts/#abstract_5279382692"&gt;Dublin&lt;/a&gt;. The interest in InfluxDB has been overwhelming and it&amp;rsquo;s encouraging to us to continue to push the project forward. Here are some interesting stats around the project.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Over 2,500 InfluxDB servers reported running in the last 24 hours&lt;/li&gt;
&lt;li&gt;Over 3,000 &lt;a href="https://github.com/influxdb/influxdb"&gt;stars on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;47 contributors to core&lt;/li&gt;
&lt;li&gt;Over 17 client libraries written by external contributors for almost every language&lt;/li&gt;
&lt;li&gt;4 command line interfaces for InfluxDB (Node, Perl, Ruby, and Go)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Despite how young InfluxDB is as an open source project, companies and other open source projects are forging ahead by deploying it into production and integrating Influx into their stack. Some of the more notable examples include &lt;a href="https://blog.heroku.com/archives/2014/8/5/new-dashboard-and-metrics-beta#heroku-metrics"&gt;Heroku building a metrics dashboard for dynos&lt;/a&gt;, &lt;a href="http://tech.gilt.com/post/98337737919/slideshows-and-photos-from-last-nights-dublin-scala-ug"&gt;Gilt building a monitoring stack&lt;/a&gt;, &lt;a href="http://dieter.plaetinck.be/influxdb-as-graphite-backend-part2.html"&gt;Dieter Plaetinick working to replace Graphite at Vimeo&lt;/a&gt;, &lt;a href="https://github.com/google/cadvisor"&gt;Google&amp;rsquo;s cAdvisor adding InfluxDB support&lt;/a&gt;, and the &lt;a href="https://wiki.openstack.org/wiki/Monasca"&gt;OpenStack Monasca project adding InfluxDB support&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id="the-road-to-1.0"&gt;The road to 1.0&lt;/h3&gt;

&lt;p&gt;With all this interest in the project we&amp;rsquo;ve had a bunch of feedback. We&amp;rsquo;ve encountered and fixed bugs and tried to be as helpful as possible with questions and feature requests. Even though there are already people running Influx in production, a 1.0 version would give more people confidence in running Influx as a key part of their stack. Here&amp;rsquo;s a list of some of the priorities we&amp;rsquo;ll be focusing on to get there:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A robust and scalable clustering implementation&lt;/li&gt;
&lt;li&gt;Tools for devops on Influx production clusters like hot backups and node replacement&lt;/li&gt;
&lt;li&gt;Revisiting the API to match more closely with the metrics use case&lt;/li&gt;
&lt;li&gt;Taking some of the common patterns that are emerging and building them into the API&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Basically, we&amp;rsquo;re focusing on stability, production use, and making sure the API is mature enough that it won&amp;rsquo;t have major changes for a while. We&amp;rsquo;ve already started much of this work and I&amp;quot;ll be writing more here and on the mailing list about changes we&amp;rsquo;ll be making to the API.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re an InfluxDB user, fan, or simply interested in what we&amp;rsquo;re doing, thank you. It&amp;rsquo;s been an incredible year and the next 12 months are going to be even better. We&amp;rsquo;ll keep shipping code and pushing to make Influx a core piece of infrastructure that delights developers and saves time and effort when building any kind of analytics or monitoring product.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Benchmarking LevelDB vs. RocksDB vs. HyperLevelDB vs. LMDB Performance for InfluxDB</title>
    <link rel="alternate" href="http://influxdb.org/blog/2014/06/20/leveldb_vs_rocksdb_vs_hyperleveldb_vs_lmdb_performance.html"/>
    <id>http://influxdb.org/blog/2014/06/20/leveldb_vs_rocksdb_vs_hyperleveldb_vs_lmdb_performance.html</id>
    <published>2014-06-19T20:00:00-04:00</published>
    <updated>2014-06-20T13:13:44-04:00</updated>
    <author>
      <name>Paul Dix</name>
    </author>
    <content type="html">&lt;p&gt;For quite some time we&amp;rsquo;ve wanted to test the performance of different storage engines for our use case with InfluxDB. We started off using LevelDB because it&amp;rsquo;s what we had used on earlier projects and RocksDB wasn&amp;rsquo;t around yet. We&amp;rsquo;ve finally gotten around to running some basic tests against a few different engines. Going forward it looks like RocksDB might be the best choice for us.&lt;/p&gt;

&lt;p&gt;However, we haven&amp;rsquo;t had the time to tune any settings or refactor things to take advantage of specific storage engine characteristics. We&amp;rsquo;re open to suggestions so read on for more detail.&lt;/p&gt;

&lt;p&gt;Before we get to results, let&amp;rsquo;s look at the test setup. We used a Digital Ocean droplet with 4GB RAM, 2 Cores, and 60GB of SSD storage.&lt;/p&gt;

&lt;p&gt;The next release of InfluxDB has a clearly defined interface for adding different storage engines. You&amp;rsquo;ll be able to choose LevelDB, RocksDB, HyperLevelDB, or LMDB. Which one you use is set through the &lt;a href="https://github.com/influxdb/influxdb/blob/master/config.sample.toml#L74-L132"&gt;configuration file&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Under the covers LevelDB is a &lt;a href="http://en.wikipedia.org/wiki/Log-structured_merge-tree"&gt;Log Structured Merge Tree&lt;/a&gt; while LMDB is a mmap copy on write &lt;a href="http://en.wikipedia.org/wiki/B%2B_tree"&gt;B+Tree&lt;/a&gt;. RocksDB and HyperLevelDB are forks of the LevelDB project that have different optimizations and enhancements.&lt;/p&gt;

&lt;p&gt;Our tests used a &lt;a href="https://github.com/influxdb/influxdb/tree/master/src/tools/benchmark-storage"&gt;benchmark tool that isolated the storage engines&lt;/a&gt; for testing. The test does the following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Write N values where the key is 24 bytes (3 ints)&lt;/li&gt;
&lt;li&gt;Query N values (range scans through the key space in ascending order and does compares to see if it should stop)&lt;/li&gt;
&lt;li&gt;Delete N/2 values&lt;/li&gt;
&lt;li&gt;Run compaction&lt;/li&gt;
&lt;li&gt;Query N/2 values&lt;/li&gt;
&lt;li&gt;Write N/2 values&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;At various steps we checked what the on disk size of the database was. We went through multiple runs writing anywhere from 1 million to 100 million values. Which implementation came out on top differed depending on how many values were in the database.&lt;/p&gt;

&lt;p&gt;For our use case we want to test on databases that have more values rather than less so we&amp;rsquo;ll focus on the results for the biggest run. We&amp;rsquo;re also not benchmarking &lt;code&gt;put&lt;/code&gt; operations on keys that already exist. It&amp;rsquo;s either inserts or deletes, which is almost always the use case with time series data.&lt;/p&gt;

&lt;p&gt;The keys consist of 3 unsigned integers that are converted into big endian bytes. The first is an id that would normally represent a time series column id, the second is a time stamp, and the third is a sequence number. The benchmark simulates values written into a number of different ids (the first 8 bytes) and increasing time stamps and sequence numbers. This is a common load pattern for InfluxDB. Single points written to many series or columns at a time.&lt;/p&gt;

&lt;p&gt;Writes during the test happen in batches of 1,000 key/value pairs. Each key/value pair is a different series column id up to the number of series to write in the test. The value is a serialized protobuf object. Specifically, it&amp;rsquo;s a &lt;a href="https://github.com/influxdb/influxdb/blob/master/src/protocol/protocol.proto#L3-L9"&gt;FieldValue&lt;/a&gt; with an &lt;code&gt;int64&lt;/code&gt; set.&lt;/p&gt;

&lt;p&gt;Here are the results of a run on 100 million values spread out over 500k columns:&lt;/p&gt;

&lt;style&gt;
table tr td {
  font-weight: normal;
}
.green {
  color: green;
  font-weight: bold;
}
.red {
  color: red;
  font-weight: bold;
}
&lt;/style&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;th&gt;Test step&lt;/th&gt;
    &lt;th&gt;LeveLDB&lt;/th&gt;
    &lt;th&gt;RocksDB&lt;/th&gt;
    &lt;th&gt;HyperLevelDB&lt;/th&gt;
    &lt;th&gt;LMDB&lt;/th&gt;
  &lt;/tr&gt;
  &lt;thead&gt;
  &lt;tr&gt;
    &lt;th&gt;Write 100M values&lt;/th&gt;
    &lt;td&gt;36m8.29s&lt;/td&gt;
    &lt;td&gt;21m18.60s&lt;/td&gt;
    &lt;td class="green"&gt;10m45.41&lt;/td&gt;
    &lt;td class="red"&gt;1h13m21.30s&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;DB Size&lt;/th&gt;
    &lt;td class="green"&gt;2.7G&lt;/td&gt;
    &lt;td&gt;3.2G&lt;/td&gt;
    &lt;td&gt;3.2G&lt;/td&gt;
    &lt;td class="red"&gt;7.6G&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;Query 100M values&lt;/th&gt;
    &lt;td&gt;2m55.37s&lt;/td&gt;
    &lt;td class="green"&gt;2m44.99s&lt;/td&gt;
    &lt;td class="red"&gt;13m49.01s&lt;/td&gt;
    &lt;td&gt;5m24.80s&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;Delete 50M values&lt;/th&gt;
    &lt;td&gt;3m47.64s&lt;/td&gt;
    &lt;td class="green"&gt;1m53.84s&lt;/td&gt;
    &lt;td&gt;6m0.38s&lt;/td&gt;
    &lt;td class="red"&gt;6m15.98s&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;Compaction&lt;/th&gt;
    &lt;td&gt;3m59.87s&lt;/td&gt;
    &lt;td class="green"&gt;3m20.27s&lt;/td&gt;
    &lt;td&gt;6m33.36s&lt;/td&gt;
    &lt;td class="red"&gt;1.548us&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;DB Size&lt;/th&gt;
    &lt;td class="green"&gt;1.4G&lt;/td&gt;
    &lt;td&gt;1.6G&lt;/td&gt;
    &lt;td&gt;1.6G&lt;/td&gt;
    &lt;td class="red"&gt;7.6G&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;Query 50M values&lt;/th&gt;
    &lt;td&gt;12.12s&lt;/td&gt;
    &lt;td&gt;13.59s&lt;/td&gt;
    &lt;td class="red"&gt;23.98s&lt;/td&gt;
    &lt;td class="green"&gt;8.48s&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;Write 50M values&lt;/th&gt;
    &lt;td&gt;3m5.28s&lt;/td&gt;
    &lt;td class="green"&gt;1m26.9s&lt;/td&gt;
    &lt;td&gt;1m54.56s&lt;/td&gt;
    &lt;td class="red"&gt;3m25.96s&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;DB Size&lt;/th&gt;
    &lt;td class="green"&gt;673M&lt;/td&gt;
    &lt;td&gt;993M&lt;/td&gt;
    &lt;td&gt;928M&lt;/td&gt;
    &lt;td class="red"&gt;2.5G&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;The test was run on the default configuration for each of the storage engines. If anyone wants to test out variations, we&amp;rsquo;d love to use the best defaults. You can play around with those in the &lt;code&gt;new&lt;/code&gt; method of each of the &lt;a href="https://github.com/influxdb/influxdb/tree/master/src/datastore/storage"&gt;storage engines&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A few interesting things come out of these results. LevelDB is the winner on disk space utilization, RocksDB is the winner on reads and deletes, and HyperLevelDB is the winner on writes. On smaller runs (30M or less), LMDB came out on top on most of the metrics except for disk size. This is actually what we&amp;rsquo;d expect for B-trees: they&amp;rsquo;re faster the fewer keys you have in them.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve marked the LMDB compaction time as a loser in red because it&amp;rsquo;s a no-op and deletes don&amp;rsquo;t actually reclaim disk space. On a normal database where you&amp;rsquo;re continually writing data, this is ok because the old pages get used up. However, it means that the DB will ONLY increase in size. For InfluxDB this is a problem because we create a separate database per time range, which we call a shard. This means that after a time range has passed, it probably won&amp;rsquo;t be getting any more writes. If we do a delete, we need some form of compaction to reclaim the disk space.&lt;/p&gt;

&lt;p&gt;On disk space utilization, it&amp;rsquo;s no surprise that the Level variants came out on top. They compress the data in blocks while LMDB doesn&amp;rsquo;t use compression.&lt;/p&gt;

&lt;p&gt;Overall it looks like RocksDB might be the best choice for our use case. However, &lt;strong&gt;there are lies, damn lies, and benchmarks&lt;/strong&gt;. Things can change drastically based on hardware configuration and settings on the storage engines.&lt;/p&gt;

&lt;p&gt;We tested on SSD because that&amp;rsquo;s where things are going (if not already there). Rocks won&amp;rsquo;t perform as well on spinning disks, but it&amp;rsquo;s not the primary target hardware for us. You could also potentially create a configuration with smaller shards and use LMDB for screaming fast performance.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a &lt;a href="https://gist.github.com/pauldix/db7dca9595e5c359ceb8"&gt;gist of more of the results from different benchmark runs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re open to updating settings, benchmarks, or adding new storage engines. In the meantime we&amp;rsquo;ll keep iterating and try to get to the best possible performance for the use case of time series data.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Free trial for InfluxDB hosting and updated documentation</title>
    <link rel="alternate" href="http://influxdb.org/blog/2014/05/21/free_trial_for_influxdb_hosting_and_updated_docs.html"/>
    <id>http://influxdb.org/blog/2014/05/21/free_trial_for_influxdb_hosting_and_updated_docs.html</id>
    <published>2014-05-20T20:00:00-04:00</published>
    <updated>2014-05-21T15:45:00-04:00</updated>
    <author>
      <name>Paul Dix</name>
    </author>
    <content type="html">&lt;p&gt;Today we&amp;rsquo;re announcing managed hosting of InfluxDB and &lt;a href="http://grafana.org/"&gt;Grafana&lt;/a&gt; (the excellent open source dashboarding solution)! Plans start at just $39 per month for a single node and an extra $49 per month for each additional node. Each InfluxDB node has 10GB of storage and you can expand the cluster at any time as your needs grow. Get up and running in under a minute by signing up for a &lt;a href="https://customers.influxdb.com/"&gt;30 day free trial of hosted InfluxDB here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re looking for help running InfluxDB on your own hardware, cloud, or behind the firewall, just a line at support@influxdb.com. We can set up and manage a cluster for you on your own servers and provide additional support.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve also &lt;a href="http://influxdb.org/docs/v0.6/introduction/getting_started.html"&gt;updated the InfluxDB documentation&lt;/a&gt;. It&amp;rsquo;s not quite complete, but the outline is there and we&amp;rsquo;ll be filling it in over the next few weeks. Or if you&amp;rsquo;re up for contributing to InfluxDB, but don&amp;rsquo;t want to write Go, pick a section that hasn&amp;rsquo;t been written yet and contribute to the docs!&lt;/p&gt;

&lt;p&gt;We have tons of exciting work coming up and the community is growing very quickly. Let us know if you need any help or just drop us a line to tell us about your use case. If there are any features you need, we prioritize based on the number of people that ask for it, so don&amp;rsquo;t hesitate to let us know.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Java is the COBOL of my generation and Go is its successor (and other reflections after GopherCon)</title>
    <link rel="alternate" href="http://influxdb.org/blog/2014/04/30/java-is-the-cobol-of-my-generation-and-go-is-its-successor.html"/>
    <id>http://influxdb.org/blog/2014/04/30/java-is-the-cobol-of-my-generation-and-go-is-its-successor.html</id>
    <published>2014-04-29T20:00:00-04:00</published>
    <updated>2014-05-20T17:27:30-04:00</updated>
    <author>
      <name>Paul Dix</name>
    </author>
    <content type="html">&lt;p&gt;Last week I attended &lt;a href="http://www.gophercon.com/"&gt;GopherCon&lt;/a&gt; in Denver, the first ever Golang conference. There were &lt;a href="https://github.com/gophercon/2014-talks"&gt;fantastic talks on Go and various projects&lt;/a&gt;, but for me the most exciting thing about the conference was meeting enthusiastic people in this nascent developer community. I came away from the event with the feeling that we&amp;rsquo;re at the beginning of a major groundswell. A massive shift in developer language use that I don&amp;rsquo;t think we&amp;rsquo;ve seen since Java came on the scene. Go&amp;rsquo;s simplicity, performance, concurrency primitives, robust implementation, and easy deployment make it ideal for server side code, web APIs, and potentially much more, which is why I think it has the potential to ultimately supplant Java.&lt;/p&gt;

&lt;p&gt;My prediction is much stronger than saying Go will be as popular as Ruby, Python, or Node. I think it&amp;rsquo;s very likely that will come to pass within a few years. While it may not be as expressive as the dynamic languages, I think its strengths will encourage a migration of many programmers from dynamic languages to Go. Anecdotally, I met and knew many Ruby developers at the conference. The dynamic language refugees are the first wave of adopters.&lt;/p&gt;

&lt;p&gt;However, to say that Go will be as big as Java is quite a stretch from saying Go will reach the popularity of the dynamic languages. Take this chart from Google Trends:&lt;/p&gt;

&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;q=golang,+/m/07sbkfb,+/m/06ff5&amp;cmpt=q&amp;content=1&amp;cid=TIMESERIES_GRAPH_0&amp;export=5&amp;w=575&amp;h=300"&gt;&lt;/script&gt;

&lt;p&gt;Java may be downward trending, but Go doesn&amp;rsquo;t even register on the Y axis, while is barely Ruby there. Go would have to be an order of magnitude more popular than Ruby to even get close to Java&amp;rsquo;s popularity.&lt;/p&gt;

&lt;p&gt;Why do I even care about popularity? Because popularity means more jobs, more potential hires, and more tools and libraries. Any developer that cares about their demand in the market (and salary potential) and any employer wishing to hire should factor language life-cycle into their language choice. I&amp;rsquo;m sure there are still COBOL programmers out there, but I wouldn&amp;rsquo;t want to be one of them if I was looking for a job and I wouldn&amp;rsquo;t want to be an employer trying to find a competent COBOL programmer or anyone that wanted to learn.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at Go&amp;rsquo;s popularity in isolation.&lt;/p&gt;

&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;q=golang&amp;cmpt=q&amp;content=1&amp;cid=TIMESERIES_GRAPH_0&amp;export=5&amp;w=575&amp;h=300"&gt;&lt;/script&gt;

&lt;p&gt;The initial spike is the announcement from Google, but on the right is the beginning of a curve that&amp;rsquo;s starting to look interesting. There were more graphs in talks at the conference that showed Go&amp;rsquo;s uptake in a practically vertical climb for the last few months.&lt;/p&gt;

&lt;p&gt;If I were a VC and I could buy options on Go as a language, I&amp;rsquo;d be seriously looking into it. Since Go is just a language they&amp;rsquo;ll have to look elsewhere: companies that are betting their tech on Go, open source projects written in Go, developer tools, and infrastructure and hosting. There were plenty of those and more at the conference. Some of the more interesting ones I met and talked to include &lt;a href="http://blog.cloudflare.com/go-at-cloudflare"&gt;Cloudflare&lt;/a&gt;, &lt;a href="http://www.hashicorp.com/"&gt;Hashicorp&lt;/a&gt;, &lt;a href="https://coreos.com/"&gt;CoreOS&lt;/a&gt;, &lt;a href="https://vividcortex.com/"&gt;VividCortex&lt;/a&gt;, &lt;a href="http://www.apcera.com/"&gt;Apcera&lt;/a&gt;, &lt;a href="http://digitalocean.com"&gt;Digital Ocean&lt;/a&gt;, and even Mozilla is building &lt;a href="https://github.com/mozilla-services/heka"&gt;Heka&lt;/a&gt; in Go despite Rust being their &amp;ldquo;in house&amp;rdquo; language under development. Then of course there&amp;rsquo;s us, &lt;a href="http://influxdb.org"&gt;InfluxDB&lt;/a&gt;, but I&amp;rsquo;m biased.&lt;/p&gt;

&lt;p&gt;I remember going to the first RailsConf in Chicago in 2006. In the months leading up to GopherCon I repeatedly told people that I felt like this first Go conference would be very similar: filled with excited technologists working with new stuff on the cusp of something great. I found it to be that, but amplified by a factor of 10. Maybe Go is just farther along than Rails was at that first conference, but I felt as though this thing will easily be bigger than Rails. People are enthusiastic about the language and things built with it. That excitement will feed into a virtuous cycle of more open source, more libraries, more books, more blog posts, and more closed source bringing more demand for Go developers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If I were a developer getting started today, I&amp;rsquo;d make a career bet on Go.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m a developer and an entrepreneur today and I&amp;rsquo;m making a major bet on Go. But, there have been other potential contenders to the Java throne in the last 10 years. Why should this one be any different? For the same reasons I listed at the top of this post: simplicity, performance, concurrency, robustness, and deployment. There are potential pitfalls for adoption that I&amp;rsquo;ll close out with, but let&amp;rsquo;s look at each of the pros in turn.&lt;/p&gt;

&lt;p&gt;First, let&amp;rsquo;s talk about simplicity. Go is a simple language by design. You can read &lt;a href="http://golang.org/ref/spec"&gt;the spec&lt;/a&gt; and other materials on the Golang website and start being productive in a single day. This is a huge strength in terms of adoption. Simple languages are easier to learn. The fantastic side effect of this is that they&amp;rsquo;re also easier to understand and read. The Go team made it very clear that they optimize for readability. This is a massive win for both newbies and for anyone working in a team or on a long lived project. Readable code is easier to maintain. Scala, a language that at one time I thought would be Java&amp;rsquo;s successor, is notoriously complex. My own experience working with it for over a year confirmed that at least for me. Simplicity is a massive win for experienced and novice developers alike and I think it&amp;rsquo;s Go&amp;rsquo;s greatest strength.&lt;/p&gt;

&lt;p&gt;Go&amp;rsquo;s performance isn&amp;rsquo;t a big win for Java developers since they&amp;rsquo;re already doing pretty well. But for us dynamic language refugees, Go&amp;rsquo;s performance is liberating. No dealing with reverse proxies to send things to multiple processes. Real threading and the ability to take advantage of every core. Async IO, but without all the callbacks. As a developer I don&amp;rsquo;t even have to try to get thousands of requests per second out of a single Go process. And if you stretch, you&amp;rsquo;ll get &lt;a href="https://cdn.rawgit.com/gophercon/2014-talks/master/derekcollison/HighPerformanceSystemsInGo.pdf"&gt;millions per second like Apcera&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Go&amp;rsquo;s concurrency primitives, namely &lt;a href="http://golang.org/ref/spec#Channel_types"&gt;channels&lt;/a&gt; and &lt;a href="http://golang.org/ref/spec#Select_statements"&gt;selects&lt;/a&gt;, make it a joy to write code that executes concurrently. Go&amp;rsquo;s design makes it easier to take advantage of every core and do IO without blocking the entire process. Both of which are big wins for anyone writing server infrastructure code.&lt;/p&gt;

&lt;p&gt;The robustness of the Go implementation is truly remarkable given its relative youth. I&amp;rsquo;ve run production Go code for over a year and any failure I&amp;rsquo;ve had so far has been entirely due to my own bugs. The language runtime itself has been rock solid. Java can make a claim to this as well, but for those of us in the dynamic community, that has not always been the case. The fact that it&amp;rsquo;s so reliable now bodes well for future improvements to the runtime.&lt;/p&gt;

&lt;p&gt;Then there&amp;rsquo;s deployment, which is fantastic with Go. Deploying Go code to production is as simple as copying a single binary file up to a server and running it. No reverse proxies, no dependencies to install on the target server, no class paths. Just copy the binary and run. For our work on InfluxDB it&amp;rsquo;s a big win when compared to what other open source time series databases require to get set up. Simple installs are great when you&amp;rsquo;re working with open source and that&amp;rsquo;ll drive many new open source projects to chose Go. We&amp;rsquo;ve already seen this in the last year with projects like &lt;a href="http://www.consul.io/"&gt;Consul&lt;/a&gt;, &lt;a href="https://github.com/coreos/etcd"&gt;etcd&lt;/a&gt;, Docker, and even CloudFoundry moving to Go.&lt;/p&gt;

&lt;p&gt;The real question is, what are the things that can impede Go&amp;rsquo;s march to dominance? Some developers have noted Go&amp;rsquo;s lack of features or a few other things: no exceptions, nils instead of options, inability to specify dependency versions, mark and sweep GC, no macros, no generics. My feeling is that almost none of these complaints will be that big of a problem. Go&amp;rsquo;s idiom for error handling pushes you in the right direction of actually handling errors instead of just bubbling them up to the top of the stack. Nils haven&amp;rsquo;t stopped plenty of other languages from gaining popularity. &lt;a href="https://github.com/tools/godep"&gt;Dependency versioning can be handled&lt;/a&gt; by tools from the OSS community. Go&amp;rsquo;s GC will get better over time unless the Go team just decides to hang up their keyboards and go live in the woods.&lt;/p&gt;

&lt;p&gt;The one complaint that gives me greatest concern is the lack of generics. I personally haven&amp;rsquo;t found it to be that big of a deal, but it can be slightly annoying when it comes to things like sorting collections. I love the simplicity of the language without generics, but it&amp;rsquo;s hard to deny that they make some things easier. But, for better or worse, the Go team has made it clear that generics aren&amp;rsquo;t coming anytime soon, if at all. So I wonder if this will limit the audience of the language or not. My gut feeling is it won&amp;rsquo;t, but in order to get to Java&amp;rsquo;s current popularity level, Go will need to attract some of those developers over to its camp.&lt;/p&gt;

&lt;p&gt;Does Java even need to be replaced? Is Go enough of a leap forward to warrant it replacing Java? I don&amp;rsquo;t think it&amp;rsquo;s a 10x increase in productivity, but it&amp;rsquo;s almost certainly an improvement. But more importantly, it IS a 10x increase in happiness for me when compared to developing in Java. And that might be enough, even if the mass of current Java developers never make the change. New developers picking Go instead of Java will be enough to shift the center of gravity over time. The shift will take decades, but if Google and the core Golang team continue to be such fantastic stewards of the language, I can imagine a future in which Go is dominant.&lt;/p&gt;

&lt;p&gt;In the meantime, I found the attendees at GopherCon and the Go community in general to be excited, intelligent, and pragmatic developers. And those are exactly the kind of developers that I want to work with, which is why I&amp;rsquo;m excited to be part of the Go community and to be building open source in the language.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>InfluxDB v0.5.0 ready for production</title>
    <link rel="alternate" href="http://influxdb.org/blog/2014/03/24/influxdb_v0_5_0_ready_for_production.html"/>
    <id>http://influxdb.org/blog/2014/03/24/influxdb_v0_5_0_ready_for_production.html</id>
    <published>2014-03-23T20:00:00-04:00</published>
    <updated>2014-03-24T15:47:34-04:00</updated>
    <author>
      <name>Paul Dix</name>
    </author>
    <content type="html">&lt;p&gt;InfluxDB version 0.5.0 has been released and is ready for production! Well, ready for production depending on your comfort level. There are &lt;a href="https://github.com/influxdb/influxdb/issues?state=open"&gt;still issues and features we want to address&lt;/a&gt;. However, there are no known bugs that cause a crash or a memory leak. This is the first release that we&amp;rsquo;re deeming production worthy. Here&amp;rsquo;s the lowdown on what we&amp;rsquo;ve added, what&amp;rsquo;s coming, and what promises we&amp;rsquo;re making for releases going forward.&lt;/p&gt;

&lt;p&gt;This release adds support for clustering. That means you can have your data split out across multiple servers for either high availability or scalability. This release also had a few big contributions from the community, which is really exciting for us. There&amp;rsquo;s support for &lt;a href="https://github.com/influxdb/influxdb/blob/master/src/configuration/config.toml#L26-L29"&gt;ingesting data via the Graphite protocol&lt;/a&gt; thanks to &lt;a href="https://github.com/Dieterbe"&gt;@Dieterbe&lt;/a&gt;. There&amp;rsquo;s a new &lt;a href="https://github.com/influxdb/influxdb/commit/e2adcf1c581dc5b6074901d11656887ffca2cdb1#diff-dcba2e0e9a976baee1338925df6ffe93R42"&gt;EXPLAIN query&lt;/a&gt; thanks to &lt;a href="https://github.com/elcct"&gt;@elcct&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Continuous queries are now supported. One great new feature with them is the ability to &lt;a href="https://github.com/influxdb/influxdb/blob/master/src/integration/server_test.go#L1311-L1368"&gt;interpolate column values into resulting series names&lt;/a&gt;. That makes it easy to denormalize series into many resulting series that are very fast to query against.&lt;/p&gt;

&lt;p&gt;Full details can be seen in the &lt;a href="https://github.com/influxdb/influxdb/blob/master/CHANGELOG.md#v050-rc1-2014-02-25"&gt;changelog from the first 0.5.0 RC forward&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Does all this mean that you can run InfluxDB in production? Well yes, if you&amp;rsquo;re comfortable running early software. We&amp;rsquo;re running it in production in a 2-node HA setup for a few customers. However, there are still a few key features that we think are quite important:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Move a shard from one node to another (for downed node replacement)&lt;/li&gt;
&lt;li&gt;Backup the database (instead of just copying all the files in /data)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the current release will handle a node in a cluster going down. Reads and writes should continue, but the assumption is that you&amp;rsquo;ll be able to bring the node back up. When it comes back up it will receieve all the data from the other nodes in the cluster that it missed while it was down. If the node is totally lost, there&amp;rsquo;s currently no way to spin up a new node and have it take the place of the downed one.&lt;/p&gt;

&lt;p&gt;Our priority for the next few point releases is to fix some of the remaining issues and add those two key features. You can expect a point release every week or two for the next few months. Future releases should not break the underlying storage format. If they do, we&amp;rsquo;ll give you a migration path. If you&amp;rsquo;re running a two node cluster, you should be able to upgrade the cluster one node at a time to avoid downtime. However, the client you&amp;rsquo;re using must support failover. We have this in the &lt;a href="https://github.com/influxdb/influxdb-ruby"&gt;InfluxDB Ruby gem&lt;/a&gt; and library authors should update their libraries to support multiple hosts.&lt;/p&gt;

&lt;p&gt;You also may have noticed that all the links in this post pointed to source code and not documentation. We&amp;rsquo;ll be going through and doing a complete update on the docs to make them easier to understand and to guide you through setting up a cluster.&lt;/p&gt;

&lt;p&gt;If you need any help drop us a line at &lt;a href="mailto:support@influxdb.com"&gt;support@influxdb.com&lt;/a&gt;, or talk to us on the &lt;a href="https://groups.google.com/forum/#!newtopic/influxdb"&gt;InfluxDB mailing list&lt;/a&gt;, or chat at us in #influxdb on freenode. If you want to start using InfluxDB, but are nervous about hosting it yourself, get in touch. We&amp;rsquo;re running production clusters for some customers already and we&amp;rsquo;re here to help you out.&lt;/p&gt;

&lt;p&gt;Go to the &lt;a href="http://influxdb.org/download/"&gt;download page&lt;/a&gt; to get the latest. Or watch this &lt;a href="https://github.com/Homebrew/homebrew/pull/27832"&gt;Homebrew PR for InfluxDB&lt;/a&gt; to see when it&amp;rsquo;s available.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>InfluxDB v0.5.0-rc1 released with all new clustering and features.</title>
    <link rel="alternate" href="http://influxdb.org/blog/2014/02/25/influxdb_v0_5_0-rc_1-released_with_new_clustering_and_features.html"/>
    <id>http://influxdb.org/blog/2014/02/25/influxdb_v0_5_0-rc_1-released_with_new_clustering_and_features.html</id>
    <published>2014-02-24T19:00:00-05:00</published>
    <updated>2014-02-25T18:14:18-05:00</updated>
    <author>
      <name>Paul Dix</name>
    </author>
    <content type="html">&lt;p&gt;InfluxDB version 0.5.0-rc1 is out! This release adds significant improvements to clustering, eviction of old data, and 99.99th percentile write performance. We&amp;rsquo;ve also added a cool new feature to continuous queries and given the admin interface some love. The goal of this RC is to put it through serious testing with different loads and failure scenarios. We&amp;rsquo;d like the 0.5.0 line to be ready for production use with a few caveats. Read on for all the details on this big new release.&lt;/p&gt;

&lt;h3 id="breaking-release"&gt;Breaking release&lt;/h3&gt;

&lt;p&gt;All the changes to clustering and the distribution of data break formats between previous releases and this one. If you&amp;rsquo;re upgrading you&amp;rsquo;ll have to blow away your old Raft and DB directories and re-import all of your data. We anticipate that this will be the last breaking change we make for a while. Future breaking changes after the 0.5.0 release will come with a migration tool so that databases can be upgraded without having to re-import everything.&lt;/p&gt;

&lt;h3 id="new-clustering-and-data-distribution"&gt;New clustering and data distribution&lt;/h3&gt;

&lt;p&gt;The previous version used a consistent hashing algorithm to distribute data across a cluster. This version changes that completely to a sharding style that distributes data based on time. Data is now distributed into shards, which are contiguous blocks of time. There are two levels of storage: long term and short term. You&amp;rsquo;re able to simply drop entire shards for either level whenever you&amp;rsquo;d like. This is a very efficient operation as it just deletes the entire LevelDB instance backing the shard. For more see &lt;a href="https://groups.google.com/forum/#!msg/influxdb/3jQQMXmXd6Q/cGcmFjM-f8YJ"&gt;this detailed writeup of how sharding and clustering work in InfluxDB&lt;/a&gt; going forward.&lt;/p&gt;

&lt;p&gt;This new style enables things like writing in high precision short term data, then automatically writing down-sampled data into longer term storage, and dropping the high precision data after some arbitrary amount of time. The down-sampling can be done automatically with continuous queries. This also makes it simple to expand clusters for new data. Simply add a server, and create upcoming shards on the new server. As the new data is written in it will go to the new servers while the old ones are still available for read queries.&lt;/p&gt;

&lt;h3 id="write-buffering"&gt;Write buffering&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ve added a write ahead log (or WAL) to this version. It fills two purposes: buffering writes to the local datastore, and keeping a short term log of writes for any server that goes down that will later need that data replayed. The write buffering to the local datastore should solve the issue with writes that take too long because of LevelDB compactions. The buffer size is configurable and will need to be larger for high volume situations.&lt;/p&gt;

&lt;h3 id="denormalizing-into-many-series-with-continuous-queries"&gt;Denormalizing into many series with continuous queries&lt;/h3&gt;

&lt;p&gt;Continuous queries received an upgrade that give them the ability to create new series from column values. For example, if you&amp;rsquo;re writing in a series called &lt;code&gt;events&lt;/code&gt; that has data like this:&lt;/p&gt;
&lt;pre class="highlight json"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"click"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"user"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"location"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"/foo.html"&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/pre&gt;

&lt;p&gt;You can now denormalize that data into streams for each user or event type with continuous queries like this:&lt;/p&gt;
&lt;pre class="highlight sql"&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;events&lt;/span&gt; &lt;span class="k"&gt;into&lt;/span&gt; &lt;span class="n"&gt;events&lt;/span&gt;&lt;span class="p"&gt;.[&lt;/span&gt;&lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;-- or this
&lt;/span&gt;&lt;span class="k"&gt;select&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;events&lt;/span&gt; &lt;span class="k"&gt;into&lt;/span&gt; &lt;span class="n"&gt;events&lt;/span&gt;&lt;span class="p"&gt;.[&lt;/span&gt;&lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="p"&gt;].[&lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;

&lt;p&gt;Since not all characters make valid series names, the values will be cleaned. &lt;code&gt;/&lt;/code&gt; turns into &lt;code&gt;.&lt;/code&gt; while spaces turn into &lt;code&gt;_&lt;/code&gt; and other invalid characters are removed. Once we enable continuous queries to start from a given timestamp, you&amp;rsquo;ll be able to backfill these indexes with old data.&lt;/p&gt;

&lt;h3 id="we-want-to-hear-from-you!"&gt;We want to hear from you!&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;ll be testing this release extensively in both single server and clustered modes under different write loads and failure scenarios. If you see anything in your testing like high memory or CPU usage, crashes, or other odd behavior, let us know on the &lt;a href="https://groups.google.com/forum/#!forum/influxdb"&gt;InfluxDB mailing list&lt;/a&gt; or at &lt;a href="mailto:support@influxdb.com"&gt;support@influxdb.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re also looking for case studies of InfluxDB in use. If you&amp;rsquo;re using InfluxDB we&amp;rsquo;d love to hear about it. We&amp;rsquo;ll send you a shirt, answer questions and give support, or generally sing your praises.&lt;/p&gt;

&lt;h3 id="caveats-on-production-use"&gt;Caveats on production use&lt;/h3&gt;

&lt;p&gt;I mentioned there would be some caveats to production use. In addition to more general testing and live use, there are a few features that we consider fairly important for using InfluxDB in production. The first is the ability to move shards between servers, which enables the replacement of downed nodes in a cluster. Version 0.6.0 will add this feature, but you could certainly run in production before this. The second is the ability to backup a database, which is also slated for the next release.&lt;/p&gt;

&lt;p&gt;That being said, if you&amp;rsquo;re comfortable using early software, we&amp;rsquo;d love to help you out. Let us know if there&amp;rsquo;s anything you need.&lt;/p&gt;

&lt;h3 id="getting-the-release"&gt;Getting the release&lt;/h3&gt;

&lt;p&gt;The latest releases have been updated for Ubuntu, Debian, RedHat, CentOS, and the source tarballs. Head to the &lt;a href="http://influxdb.org/download/"&gt;InfluxDB download page&lt;/a&gt; to grab them. If you&amp;rsquo;re on OSX, watch &lt;a href="https://github.com/Homebrew/homebrew/pull/27012"&gt;this Homebrew pull request&lt;/a&gt;. Once it&amp;rsquo;s merged in do:&lt;/p&gt;
&lt;pre class="highlight shell"&gt;brew update &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; brew install influxdb --devel
&lt;/pre&gt;

&lt;p&gt;If you&amp;rsquo;re upgrading from a previous version you&amp;rsquo;ll need to delete your Raft and DB directories.&lt;/p&gt;
</content>
  </entry>
</feed>
