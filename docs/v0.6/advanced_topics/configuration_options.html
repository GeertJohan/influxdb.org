<!DOCTYPE html><html><head><meta charset="utf-8" /><!--Always force latest IE rendering engine or request Chrome Frame--><meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible" /><!--Use title if it's in the page YAML frontmatter--><title>InfluxDB Documentation</title><script src="//fast.fonts.net/jsapi/2de9def5-2dd1-4d89-b4bb-cd7e5f821645.js" type="text/javascript"></script><link href="/stylesheets/all.css" rel="stylesheet" type="text/css" /><script src="/javascripts/all.js" type="text/javascript"></script></head><body class="docs docs_v0"><header class="navigation"><div class="menu-wrapper"><a class="logo" href="/"><img src="/images/influxdb-light400.png" /></a><p class="navigation-menu-button" id="js-mobile-menu">MENU</p><div class="nav"><ul id="navigation-menu"><li class="nav-link"><a href="/docs/v0.8/introduction/overview.html">Overview</a></li><li class="nav-link"><a target="blank" href="https://customers.influxdb.com">Support & Hosting</a></li><li class="nav-link"><a href="/blog">Blog</a></li><li class="nav-link"><a href="/docs/v0.8/introduction/getting_started.html">Docs</a></li><li class="nav-link"><a href="/community">Community</a></li><li class="nav-link"><a target="blank" href="http://play.influxdb.org">Play</a></li></ul></div><div class="navigation-tools"><a class="sign-up" href="/download">Download</a></div></div></header><section role="main"><div class="row"><div class="large-4 medium-4 columns"><div class="sidebar"><nav><ul class="side-nav"><li class="heading">Introduction</li><li><a href="/docs/v0.6/introduction/overview.html">Overview</a></li><li><a href="/docs/v0.6/introduction/installation.html">Installation</a></li><li><a href="/docs/v0.6/introduction/getting_started.html">Getting Started</a></li><li class="divider"></li><li class="heading">API</li><li><a href="/docs/v0.6/api/reading_and_writing_data.html">Reading & Writing Data</a></li><li><a href="/docs/v0.6/api/query_language.html">Query Language</a></li><li><a href="/docs/v0.6/api/aggregate_functions.html">Aggregate Functions</a></li><li><a href="/docs/v0.6/api/continuous_queries.html">Continuous Queries</a></li><li><a href="/docs/v0.6/api/chunked_responses.html">Chunked HTTP Responses</a></li><li><a href="/docs/v0.6/api/administration.html">Administration</a></li><li class="divider"></li><li class="heading">UI</li><li><a href="/docs/v0.6/ui/built_in_admin_and_explorer.html">Built-in Admin and Explorer Interface</a></li><li><a href="/docs/v0.6/ui/grafana.html">Grafana Dashboards</a></li><li><a href="https://github.com/hakobera/influga">Influga Dashboards</a></li><li class="divider"></li><li class="heading">Advanced Topics</li><li><a href="/docs/v0.6/advanced_topics/sharding_and_storage.html">Underlying Storage and Shards</a></li><li><a href="/docs/v0.6/advanced_topics/configuration_options.html">Configuration Options</a></li><li><a href="/docs/v0.6/advanced_topics/schema_design.html">Schema Design</a></li><li><a href="/docs/v0.6/advanced_topics/performance_considerations.html">Performance Considerations</a></li><li><a href="/docs/v0.6/advanced_topics/security.html">Security</a></li><li class="divider"></li><li class="heading">Clustering</li><li><a href="/docs/v0.6/clustering/design.html">Design</a></li><li><a href="/docs/v0.6/clustering/setup.html">Setup</a></li><li class="divider"></li><li class="heading">Future Features</li><li><a href="/docs/v0.6/future/binary_protocol.html">Binary Protocol</a></li><li><a href="/docs/v0.6/future/pubsub.html">Pubsub</a></li><li><a href="/docs/v0.6/future/column_indexes.html">Column Indexes and Tags</a></li><li><a href="/docs/v0.6/future/shard_spaces.html">Shard Spaces and Retention Policies</a></li><li><a href="/docs/v0.6/future/custom_functions.html">Custom Functions</a></li><li><a href="/docs/v0.6/future/security.html">Security Enhancements</a></li><li class="divider"></li><li class="heading">Client Libraries</li><li><a href="/docs/v0.6/client_libraries/javascript.html">JavaScript</a></li><li><a href="https://github.com/influxdb/influxdb-ruby">Ruby</a></li><li><a href="https://github.com/influxdb/influxdb-rails">Rails</a></li><li><a href="/docs/v0.6/client_libraries/python.html">Python</a></li><li><a href="/docs/v0.6/client_libraries/node.html">Node.js</a></li><li><a href="/docs/v0.6/client_libraries/php.html">PHP</a></li><li><a href="https://github.com/majst01/influxdb-java">Java</a></li><li><a href="https://github.com/olauzon/capacitor">Clojure</a></li><li><a href="https://github.com/mmaul/cl-influxdb">Common Lisp</a></li><li><a href="https://github.com/davidB/metrics-influxdb">Java Metrics</a></li><li><a href="https://github.com/influxdb/influxdb-go">Go</a></li><li><a href="https://github.com/rcrowley/go-metrics">Go Metrics</a></li><li><a href="https://github.com/influxdb/influxdb-scala">Scala</a></li><li><a href="https://github.com/influxdb/influxdb-r">R</a></li><li><a href="https://metacpan.org/pod/InfluxDB">Perl</a></li><li><a href="https://github.com/maoe/influxdb-haskell">Haskell</a></li><li class="divider"></li><li class="heading">Contributing</li><li><a href="/community/cla.html">CLA</a></li><li><a href="https://github.com/influxdb/influxdb.org">To this Documentation</a></li><li><a href="https://github.com/influxdb/influxdb/blob/master/LICENSE">License (MIT)</a></li><li><a href="/docs/v0.6/contributing/building.html">Building From Source</a></li><li class="divider"></li><li class="heading">Other Libraries and Tools</li><li><a href="https://github.com/FGRibreau/influxdb-cli">CLI (Node)</a></li><li><a href="https://github.com/phstc/influxdb-cli">CLI (Ruby)</a></li><li><a href="http://grafana.org/">Grafana (dashboards)</a></li><li><a href="https://github.com/obfuscurity/tasseo">Tasseo (realtime dashboard)</a></li><li><a href="https://github.com/bernd/statsd-influxdb-backend">StatsD Backend</a></li><li><a href="https://github.com/bpaquet/collectd-influxdb-proxy">CollectD Proxy</a></li><li><a href="https://github.com/fangli/fluent-plugin-influxdb">FluentD Plugin</a></li><li><a href="https://github.com/lusis/sensu_influxdb_handler">Sensu Handler</a></li><li><a href="https://github.com/SimpleFinance/chef-handler-influxdb">Chef Handler/Reporter</a></li><li><a href="https://github.com/CargoSense/puppet-influxdb">Config Management via Boxen</a></li><li class="divider"></li><li class="heading">Docs Versions</li><li><a href="/docs/v0.6/introduction/overview.html">v0.6</a></li><li><a href="/docs/v0.7/introduction/overview.html">v0.7</a></li><li><a href="/docs/v0.8/introduction/overview.html">v0.8</a></li></ul></nav><a class="button download expand" href="/download" style="margin-bottom: 0;">Download InfluxDB</a></div></div><div class="large-8 medium-8 columns" id="docs"><h1 id="configuration">Configuration</h1>

<p>Here&rsquo;s a sample configuration file. Comments in the file explain the options.</p>
<pre class="highlight toml"><span class="c"># Welcome to the InfluxDB configuration file.</span>

<span class="c"># If hostname (on the OS) doesn't return a name that can be resolved by the other</span>
<span class="c"># systems in the cluster, you'll have to set the hostname to an IP or something</span>
<span class="c"># that can be resolved here.</span>
<span class="c"># hostname = ""</span>

<span class="py">bind-address</span> <span class="p">=</span> <span class="s">"0.0.0.0"</span>

<span class="c"># Once every 24 hours InfluxDB will report anonymous data to m.influxdb.com</span>
<span class="c"># The data includes raft name (random 8 bytes), os, arch and version</span>
<span class="c"># We don't track ip addresses of servers reporting. This is only used</span>
<span class="c"># to track the number of instances running and the versions which</span>
<span class="c"># is very helpful for us.</span>
<span class="c"># Change this option to true to disable reporting.</span>
<span class="py">reporting-disabled</span> <span class="p">=</span> <span class="kc">false</span>

<span class="nn">[logging]</span>
<span class="c"># logging level can be one of "debug", "info", "warn" or "error"</span>
<span class="py">level</span>  <span class="p">=</span> <span class="s">"info"</span>
<span class="py">file</span>   <span class="p">=</span> <span class="s">"influxdb.log"</span>         <span class="c"># stdout to log to standard out</span>

<span class="c"># Configure the admin server</span>
<span class="nn">[admin]</span>
<span class="py">port</span>   <span class="p">=</span> <span class="mi">8083</span>              <span class="c"># binding is disabled if the port isn't set</span>
<span class="py">assets</span> <span class="p">=</span> <span class="s">"./admin"</span>

<span class="c"># Configure the http api</span>
<span class="nn">[api]</span>
<span class="py">port</span>     <span class="p">=</span> <span class="mi">8086</span>    <span class="c"># binding is disabled if the port isn't set</span>
<span class="c"># ssl-port = 8084    # Ssl support is enabled if you set a port and cert</span>
<span class="c"># ssl-cert = /path/to/cert.pem</span>

<span class="c"># connections will timeout after this amount of time. Ensures that clients that misbehave </span>
<span class="c"># and keep alive connections they don't use won't end up connection a million times.</span>
<span class="c"># However, if a request is taking longer than this to complete, could be a problem.</span>
<span class="py">read-timeout</span> <span class="p">=</span> <span class="s">"5s"</span>

<span class="nn">[input_plugins]</span>

  <span class="c"># Configure the graphite api</span>
  <span class="nn">[input_plugins.graphite]</span>
  <span class="py">enabled</span> <span class="p">=</span> <span class="kc">false</span>
  <span class="c"># port = 2003</span>
  <span class="c"># database = ""  # store graphite data in this database</span>

<span class="c"># Raft configuration</span>
<span class="nn">[raft]</span>
<span class="c"># The raft port should be open between all servers in a cluster.</span>
<span class="c"># However, this port shouldn't be accessible from the internet.</span>

<span class="py">port</span> <span class="p">=</span> <span class="mi">8090</span>

<span class="c"># Where the raft logs are stored. The user running InfluxDB will need read/write access.</span>
<span class="py">dir</span>  <span class="p">=</span> <span class="s">"/tmp/influxdb/development/raft"</span>

<span class="c"># election-timeout = "1s"</span>

<span class="nn">[storage]</span>
<span class="py">dir</span> <span class="p">=</span> <span class="s">"/tmp/influxdb/development/db"</span>
<span class="c"># How many requests to potentially buffer in memory. If the buffer gets filled then writes</span>
<span class="c"># will still be logged and once the local storage has caught up (or compacted) the writes</span>
<span class="c"># will be replayed from the WAL</span>
<span class="py">write-buffer-size</span> <span class="p">=</span> <span class="mi">10000</span>

<span class="nn">[cluster]</span>
<span class="c"># A comma separated list of servers to seed</span>
<span class="c"># this server. this is only relevant when the</span>
<span class="c"># server is joining a new cluster. Otherwise</span>
<span class="c"># the server will use the list of known servers</span>
<span class="c"># prior to shutting down. Any server can be pointed to</span>
<span class="c"># as a seed. It will find the Raft leader automatically.</span>

<span class="c"># Here's an example. Note that the port on the host is the same as the raft port.</span>
<span class="c"># seed-servers = ["hosta:8090","hostb:8090"]</span>

<span class="c"># Replication happens over a TCP connection with a Protobuf protocol.</span>
<span class="c"># This port should be reachable between all servers in a cluster.</span>
<span class="c"># However, this port shouldn't be accessible from the internet.</span>

<span class="py">protobuf_port</span> <span class="p">=</span> <span class="mi">8099</span>
<span class="py">protobuf_timeout</span> <span class="p">=</span> <span class="s">"2s"</span> <span class="c"># the write timeout on the protobuf conn any duration parseable by time.ParseDuration</span>
<span class="py">protobuf_heartbeat</span> <span class="p">=</span> <span class="s">"200ms"</span> <span class="c"># the heartbeat interval between the servers. must be parseable by time.ParseDuration</span>
<span class="py">protobuf_min_backoff</span> <span class="p">=</span> <span class="s">"1s"</span> <span class="c"># the minimum backoff after a failed heartbeat attempt</span>
<span class="py">protobuf_max_backoff</span> <span class="p">=</span> <span class="s">"10s"</span> <span class="c"># the maximum backoff after a failed heartbeat attempt</span>

<span class="c"># How many write requests to potentially buffer in memory per server. If the buffer gets filled then writes</span>
<span class="c"># will still be logged and once the server has caught up (or come back online) the writes</span>
<span class="c"># will be replayed from the WAL</span>
<span class="py">write-buffer-size</span> <span class="p">=</span> <span class="mi">10000</span>

<span class="c"># the maximum number of responses to buffer from remote nodes, if the</span>
<span class="c"># expected number of responses exceed this number then querying will</span>
<span class="c"># happen sequentially and the buffer size will be limited to this</span>
<span class="c"># number</span>
<span class="py">max-response-buffer-size</span> <span class="p">=</span> <span class="mi">100000</span>

<span class="c"># When queries get distributed out to shards, they go in parallel. This means that results can get buffered</span>
<span class="c"># in memory since results will come in any order, but have to be processed in the correct time order.</span>
<span class="c"># Setting this higher will give better performance, but you'll need more memory. Setting this to 1 will ensure</span>
<span class="c"># that you don't need to buffer in memory, but you won't get the best performance.</span>
<span class="py">concurrent-shard-query-limit</span> <span class="p">=</span> <span class="mi">10</span>

<span class="nn">[leveldb]</span>

<span class="c"># Maximum mmap open files, this will affect the virtual memory used by</span>
<span class="c"># the process</span>
<span class="py">max-open-files</span> <span class="p">=</span> <span class="mi">40</span>

<span class="c"># LRU cache size, LRU is used by leveldb to store contents of the</span>
<span class="c"># uncompressed sstables. You can use `m` or `g` prefix for megabytes</span>
<span class="c"># and gigabytes, respectively.</span>
<span class="py">lru-cache-size</span> <span class="p">=</span> <span class="s">"200m"</span>

<span class="c"># The default setting on this is 0, which means unlimited. Set this to something if you want to</span>
<span class="c"># limit the max number of open files. max-open-files is per shard so this * that will be max.</span>
<span class="py">max-open-shards</span> <span class="p">=</span> <span class="mi">0</span>

<span class="c"># The default setting is 100. This option tells how many points will be fetched from LevelDb before</span>
<span class="c"># they get flushed into backend.</span>
<span class="py">point-batch-size</span> <span class="p">=</span> <span class="mi">100</span>

<span class="c"># These options specify how data is sharded across the cluster. There are two</span>
<span class="c"># shard configurations that have the same knobs: short term and long term.</span>
<span class="c"># Any series that begins with a capital letter like Exceptions will be written</span>
<span class="c"># into the long term storage. Any series beginning with a lower case letter</span>
<span class="c"># like exceptions will be written into short term. The idea being that you</span>
<span class="c"># can write high precision data into short term and drop it after a couple</span>
<span class="c"># of days. Meanwhile, continuous queries can run downsampling on the short term</span>
<span class="c"># data and write into the long term area.</span>
<span class="nn">[sharding]</span>
  <span class="c"># how many servers in the cluster should have a copy of each shard.</span>
  <span class="c"># this will give you high availability and scalability on queries</span>
  <span class="py">replication-factor</span> <span class="p">=</span> <span class="mi">1</span>

  <span class="nn">[sharding.short-term]</span>
  <span class="c"># each shard will have this period of time. Note that it's best to have</span>
  <span class="c"># group by time() intervals on all queries be &lt; than this setting. If they are</span>
  <span class="c"># then the aggregate is calculated locally. Otherwise, all that data gets sent</span>
  <span class="c"># over the network when doing a query.</span>
  <span class="py">duration</span> <span class="p">=</span> <span class="s">"7d"</span>

  <span class="c"># split will determine how many shards to split each duration into. For example,</span>
  <span class="c"># if we created a shard for 2014-02-10 and split was set to 2. Then two shards</span>
  <span class="c"># would be created that have the data for 2014-02-10. By default, data will</span>
  <span class="c"># be split into those two shards deterministically by hashing the (database, series)</span>
  <span class="c"># tuple. That means that data for a given series will be written to a single shard</span>
  <span class="c"># making querying efficient. That can be overridden with the next option.</span>
  <span class="py">split</span> <span class="p">=</span> <span class="mi">1</span>

  <span class="c"># You can override the split behavior to have the data for series that match a</span>
  <span class="c"># given regex be randomly distributed across the shards for a given interval.</span>
  <span class="c"># You can use this if you have a hot spot for a given time series writing more</span>
  <span class="c"># data than a single server can handle. Most people won't have to resort to this</span>
  <span class="c"># option. Also note that using this option means that queries will have to send</span>
  <span class="c"># all data over the network so they won't be as efficient.</span>
  <span class="c"># split-random = "/^hf.*/"</span>

  <span class="nn">[sharding.long-term]</span>
  <span class="py">duration</span> <span class="p">=</span> <span class="s">"30d"</span>
  <span class="py">split</span> <span class="p">=</span> <span class="mi">1</span>
  <span class="c"># split-random = "/^Hf.*/"</span>

<span class="nn">[wal]</span>

<span class="py">dir</span>   <span class="p">=</span> <span class="s">"/tmp/influxdb/development/wal"</span>
<span class="py">flush-after</span> <span class="p">=</span> <span class="mi">1000</span> <span class="c"># the number of writes after which wal will be flushed, 0 for flushing on every write</span>
<span class="py">bookmark-after</span> <span class="p">=</span> <span class="mi">1000</span> <span class="c"># the number of writes after which a bookmark will be created</span>

<span class="c"># the number of writes after which an index entry is created pointing</span>
<span class="c"># to the offset of the first request, default to 1k</span>
<span class="py">index-after</span> <span class="p">=</span> <span class="mi">1000</span>

<span class="c"># the number of requests per one log file, if new requests came in a</span>
<span class="c"># new log file will be created</span>
<span class="py">requests-per-logfile</span> <span class="p">=</span> <span class="mi">10000</span>
</pre>
</div></div></section><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-45024174-1', 'influxdb.com');
ga('send', 'pageview');</script><script type="text/javascript">(function() {
  $("#docs h1, #docs h2, #docs h3, #docs h4").each(function(i, el) {
    var id, text;
    id = el.id;
    text = $(el).text();
    return $(el).html('<a href="#' + id + '">' + text + '</a>');
  });

}).call(this);
</script></body></html>